## 概要

平たく言えば、重回帰分析とは、単回帰分析では目的変数に最も関連のある説明変数を使って直線を引いていましたが、重回帰分析では複数の説明変数を用いて直線を引くこと分析方法です。

# この章の目標

**推定完了時間: １時間30分**

　先ほど単回帰分析を学びました。このモデルの性能を上げていくようにするにはどのようにしたらよいでしょうか？単回帰は１つの変数でしたが、複数の変数を用いる重回帰分析と呼ばれる違う分析手法を用いてみましょう。

**1. scikit-learnの重回帰分析の手法を学習しよう**

# 重回帰分析とは

　重回帰分析は、複数の説明変数から目的変数を予測する回帰分析のことを言います。裏の理論は高校数学で理解できるものではないので一旦置いておいて、まず使えるようになりましょう。
　高校数学で理解できるものではないですが、一旦下に一般式を載せておきますので興味があったら調べてみてください！

$$y = \sum_{m=1}^{M}w_mx_m + b $$

## 用いるデータを確認しよう

　まず、用いるデータの確認をしましょう。データは**目的変数['target']**と**説明変数['LSTAT']**のままですね。ここになんのデータを追加しましょう？
　再びヒートマップをみてみましょう！

　![](/media/editor/D-8ヒートマップ_20201130143251959305.png)

　RMがLSTATの次にボストンの住宅価格に関連度が強いことが見れれますので、こちらの変数を追加してやってみたいと思います。どれでは、変数を追加する方法を学んでいきましょう。

## 重回帰分析を行おう

　重回帰分析を行うにあたって、注意点があります。先ほどのような住宅価格とLSTATの値を比較して、直線を引くというのは重回帰分析を行う上であまりしません。これはなぜでしょうか？
　<font color='red'>**重回帰分析は変数が2つとは限りませんよね。計算能力が許す限り、100変数に対しても、いくつの変数に対しても行うことが理論上はできます**</font>。ですので、グラフにプロットしきれないのです。ですので、先ほどの散布図と直線のコードはコメントアウトするか、散布図と直線のコード以外を別のコードブロックへコピーしてから進めましょう。
　では早速いきましょう。まず、reshapeする必要がなくなったので、reshapeを削除します。この理由は、行列を学んだらわかるので、もうちょっと先の数学まで我慢です。そして、先ほど見た**RM**を学習・検証データ双方から取り出していきましょう。

###### <font color='red'>RMをtrainとtestデータから取り出してみよう</font>

```python
   # 訓練データとテストデータの作成
   X_train = train[["RM", "LSTAT"]]
   Y_train = train["target"] #修正済み住宅価格中央値
   X_test = test[["RM", "LSTAT"]]
   Y_test = test["target"]
```

　はい、これもこれで終了です。実は、**LinearRegression()モデルは、重回帰分析も単回帰分析**も渡す変数の違いによって行うことができるモデルなのです。ですので、これだけでできてしまいます。
　性能を図る部分のコードも変数名さえ間違っていなければそのまま動きます！
　早速実行して性能をみましょう！

こちらから全体のコードも確認してみましょう

[全体コード](/answer/23)

## 各指標をみてみよう

```python
#単回帰分析のとき
RMSE train data:  6.043506135262846
RMSE test data:  6.807077593213252
MSE train data:  36.52396640695966
MSE test data:  46.336305360025925
R^2 
 Train : 0.571031588576562 
 Test : 0.43095672846187605
# 重回帰分析のとき
RMSE train data:  5.365657134224422
RMSE test data:  6.114172522817781
MSE train data:  28.790276482053443
MSE test data:  37.38310563877995
R^2
 Train : 0.6618625964841893
 Test : 0.5409084827186418
```

単回帰分析よりも重回帰分析の方が精度がよくなっていますね。これは、変数を多く分析に使ったため精度がよくなっています。

### 今回行った分析で得られた結果というのはどのようなものなのか？
　今回得られた式の意味を一回考えてみましょう。
　この式の意味を理解することは非常に重要です。式そのものを日本語に翻訳でき、相手に伝えることも人工知能エンジニアやデータサイエンティストの評価されるスキルのひとつです。それは、いくらデータ解析が上手くても、解析しただけでは意味がないからです。それでは、各変数の係数を求めていきましょう。
　下記のコードを実行してみましょう。

```python
pd.DataFrame({"name":X_train.columns,"coefficients":model.coef_})
```

　以下のように各変数と変数の係数が出てきたと思います。この変数の意味を考えてみましょう

||name  |coefficients|
|:--:|:--:|:--:|
|0 |    RM|      5.109068|
|1 | LSTAT|     -0.654949|

これは、
$$TARGET = 5.1RM -0.65LSTAT + 切片$$
という結果を導いています。この結果は、**部屋数の指標はプラスに働き、貧困人口割合の指標はマイナスに働いているということを示しています**。これはおおよそ大半の人の感覚と正しいのではないでしょうか？

### さらに精度をあげてみよう
　ここからさらに精度をあげてみたいと思います。次章ではまた異なる分析手法を用いてみたいと思います。

# まとめ
　重回帰分析を駆け足ですが用いてみました。どのように計算されているか知らなくてもできてしまうというのが便利なところです。
　深くまで知らなくても使うことができますが、なんでこうなっているんだろうという気持ち悪さもあるかと思います。
　ぜひ興味があれば学習してみてください。重回帰分析は「n次元のベクトルの最小二乗法」を学習すると理解できるはずです。