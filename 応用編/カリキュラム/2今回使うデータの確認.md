## 概要

scikit-learnの付属データであるトイデータセットを使います。トイデータセットというのは、通常の機械学習で使うものと比べるとデータ数が少ないデータセットです。ですが、学習に使うのにはインストールして付属してくるので使い勝手が良いいので今回こちらのデータセットのうち、ボストンの住宅価格データを使います。そのデータについて理解しましょう。

# この章の目標
　scikit-learnのデータの内容について学習します。また、今回学習するデータについて中身をみてみましょう。

**推定完了時間:30分**

**1. scikit-learnのボストンの住宅価格データについて理解する**


# scikit-learnとは

  scikit-learn（サイキット・ラーン）はPython用の機械学習ライブラリです。scikit-learnはオープンソースで公開されており、誰でも無料で利用することが出来ます。また、教師あり学習、教師なし学習に関するアルゴリズムが一通り利用できます。このなかに今回使う単回帰分析、重回帰分析、多項式回帰が含まれています。

## scikit-learnのデータセット

　scikit-learnには、付属データとして**トイデータセット**が付属しています。トイデータセットというのは、通常の機械学習で使うものと比べるとデータ数が少ないデータセットです。ですが、学習に使うのにはインストールして付属してくるので使い勝手がいいので今回はこちらを使います。
　また、トイデータセットの中でも、ボストンの住宅価格のデータセットを使います。
　ほかのデータセットは以下の表に記載されています。

|データセット名|呼び出し方|
|:--:|:--:|
|ボストンの住宅価格|load_boston()|
|アイリス（アヤメ）の種類|load_iris()|
|糖尿病の進行状況|load_diabetes()|
|手書き文字（数字）|load_digits|
|生理学的測定結果と運動測定結果|load_linnerud()|
|ワインの種類|load_wine()|
|がんの診断結果|load_breast_cancer()|

# ボストンの住宅価格のデータセットについて知ろう

　ボストンの住宅価格のデータセットのデータをGoogle Colabで読み込んで実際に見てみましょう。

## データを知るためには何が必要でしょうか？

　データの概要を把握することはデータサイエンティストやAIエンジニアにとって大切です。では、データを見るときに何をみたらそのデータの大まかな内容が把握できるでしょうか？考えてみましょう。
　データを分析の指標はたくさんあります。
　例えば、まずデータを表にした時の項目名やその行数と列の数、これはどれくらいのデータの大きさなのか、どんなデータなのかの指標になります。
　次に、最大値最小値、平均値などを求める方法があります。これは、そのデータの広がり具合を示す指標によく使われます。皆さんですと箱ひげ図が馴染み深いのではないでしょうか？
　それでは１つづつみていき、データの概要を掴んでみましょう。

## データセットを読み込む

  <font color='red'>**import**</font>文で読み込んでみましょう。

###### <font color='red'>ボストンの住宅価格を読みこもう</font>

```python
from sklearn.datasets import load_boston
```

## 読み込んだデータセットを表示して詳細をみよう

  これだけで実行しても何も表示されません。それはそうですね、読み込んでいるだけですから。そこで、トイデータの中身を表示する<font color='red'>**DESCR**</font>というメソッドを使ってload_bostonの詳細データをprintしてみましょう。


### どんなデータなのかみてみよう
  以下のコードを実行してみてください。そうすると、データを表にした時の項目名などを見ることができます。

```python
  dataset = load_boston()
  # dataset.DESCR を表示すると、データセットの概要が表示されます。
  print(dataset.DESCR)
```

  すると、以下のようにデータセットの詳細が表示されたはずです。

```python
  Boston house prices dataset
  ---------------------------

  **Data Set Characteristics:**

    :Number of Instances: 506 

    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.

    :Attribute Information (in order):
      - CRIM     per capita crime rate by town
      - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
      - INDUS    proportion of non-retail business acres per town
      - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
      - NOX      nitric oxides concentration (parts per 10 million)
      - RM       average number of rooms per dwelling
      - AGE      proportion of owner-occupied units built prior to 1940
      - DIS      weighted distances to five Boston employment centres
      - RAD      index of accessibility to radial highways
      - TAX      full-value property-tax rate per $10,000
      - PTRATIO  pupil-teacher ratio by town
      - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
      - LSTAT    % lower status of the population
      - MEDV     Median value of owner-occupied homes in $1000's
```

英語のままで難しいと思いますのでいかに日本語訳を用意しました。参考までにどうぞ。

|英語カラム名|日本語カラム名|
|:--:|:--|
|CRIM|1人当たりの犯罪数|
|ZN|町別の25,000平方フィート(7600m2)以上の住居区画の割合|
|INDUS|町別の非小売業が占める土地面積の割合|
|CHAS|チャールズ川沿いかどうか|
|NOX|町別の窒素酸化物の濃度（1000万分の1）|
|RM|住居の平均部屋数|
|AGE|持ち家住宅|
|DIS|5つのボストン雇用センターへの重み付き距離|
|TAX|町別の$10,000ドルあたりの固定資産税率|
|PTRATIO|町別の生徒と先生の比率|
|TRACT|土地番号|
|B|1000*(黒人人口割合 - 0.63)2割合が低いとスコアが高くなるようになっている。|
|LSTAT|貧困人口割合|
|MEDV|持家住宅の価格(1000USD単位)|

　これらは、カラム名と呼ばれます。表の項目名に当たるような部分です。

### データの大きさ
次に、何行何列のデータなのかを上の結果からみてみましょう。

```python
:Number of Instances: 506 
:Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.
```

の部分では、「データの行数は506あり、答え（教師データ）を含んで列数は14列ありますよ」「要素の14番目は目的変数です」と教えてくれています。英語に臆することなく前に進みましょう。

![](/media/editor/D-2行と列について_20201130142002131670.png)


### もっとデータの概要を把握しよう

　次に、最大値最小値、平均値などを求めるますが、scikit-learnだけで求められなくもないですが、もっと簡単に求めるモジュールがありますので次章でご紹介したいと思います。まずは、今回の章の復習をしっかりしていきましょう。

# まとめ
今回は使用するボストンの住宅価格のデータはどのようなデータなのかといのをみていきました。
　実際に学習に使うデータはいくらくらいの大きさなのだろうかということが疑問に浮かぶかと思います。実際に使われるデータは一般的に１０キロ〜メガスケールであることが多いです。
　今回示したデータの特徴はデータが何行何列なのかという直接的な大きさを示すものです。
　データの特徴を示す値はもっとたくさんあります。これからそれをみていきましょう。