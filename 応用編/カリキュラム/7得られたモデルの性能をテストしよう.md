## 概要

モデルのテストというモデルの性能評価試験のようなものを行なっていきます。その手法と結果の分析方法を学びましょう。

# この章の目標

**推定完了時間: １時間30分**

　作成したモデルが本当に未来を予測できるのでしょうか？未来を優れた精度で予測できるモデルかどうかそれを検証する手法を学びましょう。

**1. scikit-learnを用いて、モデルの正確性を保証する手法を学びましょう。**

# モデルのテストについて
　構築したモデルを今後利用することを考えると、モデル構築の際にモデルが得られない将来のデータに対して精度よく予測できるかがそのモデルの性能の重要なポイントです。ですので、学習に用いていないデータでモデルを検証する必要があります。そのため、**手元のデータを学習データと検証データにわけ、学習データでモデルを構築し、検証データを将来のデータと見立て、これに対するモデルの性能を評価します**。この評価方法を実際にやりながら学んでいきましょう。

## データのテストとトレーニングに2分割
　まず、手元のデータを学習データと検証データに分割します。
　分割する方法もたくさんありますが、ホールドアウト法という手法で分割します。他の分割方法に興味があれば調べてみましょう。
　実際に、これをどのようにホールドアウト法で分割するのでしょうか？実は、分割するための関数がscikit-learn内に用意されています。それが、**sckit-learnのmodel_selectionのtrain_test_split関数**というものです。
　引数には、分割するデータ、学習データと検証データの比率である"test_size"などを指定します。
　引数のrandom_stateを0にすることでランダムではなく毎回同じ結果を返すことができます。以後に表示する結果は変わってしまいますので指定することをお勧めします。
　以下に構文を示します。

```python
from sklearn.model_selection import train_test_split
train, test = train_test_split(データ, 引数)
```

###### <font color='red'>実際に、ボストンの住宅価格のデータセットを学習データと検証データに分けてみましょう。実際に、ボストンの住宅価格のデータセットを学習データと検証データに分けてみましょう。</font>

　ここでは検証データとテストデータをtrain、testという名前で分けています。
　下記のコードを追加してデータを分割しましょう。ただし、データ分割の記述はDataFrame作成以降に書かなければエラーになってしまいます。ので注意してください。

```python
from sklearn.model_selection import train_test_split
train, test = train_test_split(dfa, test_size=0.20, random_state=0)
```

　これで、学習データと検証データに分割できました。

#### <font color='blue'>学習に全データを用いていたので、書き換えて学習には学習データを使うように書き換えましょう。</font>

　trainデータからどうやってLSTATとTARGETを取得するか考えてみましょう。

ちなみに、以下で検証データと学習データの分割数をみることができます。

```python
train.count()
test.count()
```

##### [演習解答](/answer/22)

では、実際にあらゆる数値を用いて学習したモデルの正確性を測っていきましょう。

## 評価に用いる値
　評価に用いる値はいくつかありますが、今回は以下の3つの値を用います。

- 二乗平均平方根誤差（RMSE）と平均二乗誤差（MSE）
- 決定係数
- 残差プロット

をここで紹介します。


### 二乗平均平方根誤差（RMSE）と平均二乗誤差（MSE）

　誤差の二乗を平均して平方根をとったものです。RMSEは統計学の世界では最もよく使われる指標です。RMSEは以下の手順で求めています。

1. **予測した値と実際の値との誤差をとります**
2. **その誤差の値を2乗し、その総和をとります**
3. **総和をデータの件数で割って平均を取ります**
4. **最後に平方根を取ります**

　また、式で示すと以下のように示されます。理解する必要は必ずしもありません。

$$MSE = \frac{1}{n} \sum_{i=0}^{n-1} (y_i - \hat{y_i})^2$$
$$RMSE = \sqrt{\frac{1}{n} \sum_{i=0}^{n-1} (y_i - \hat{y_i})^2}$$
$$但し、 y_i=実際の値、\hat{y}=予測値、 n=データの総数 $$

　予測と正解の平均的なズレを表しており、大きな誤差を厳しく評価する特徴があります。
　実際にどのように求めていくのかみていきましょう。

###### <font color='red'>pythonでMSEとRMSEを求めよう</font>

　MSEを求めるためには、scikit-learnのmean_squared_error関数を使います。また、RMSEはMSEの平方根ですので、平方根を計算するためのmathモジュールからsqrtを呼び出しています。
　**scikit-learnのmean_squared_error関数**は引数に$y$と$\hat{y}$をとります。

```python
from math import sqrt
from sklearn.metrics import mean_squared_error

# 学習データに対する目的変数を予測
Y_train_pred = lr.predict(X_train)
# 検証データに対する目的変数を予測
Y_pred = lr.predict(X_test)
# 学習データを用いたときの二乗平均平方根誤差(RMSE)を算出
print('RMSE train data: ', sqrt(mean_squared_error(Y_train, Y_train_pred))) 
# 検証データを用いたときの二乗平均平方根誤差(RMSE)を算出
print('RMSE test data: ', sqrt(mean_squared_error(Y_test, Y_pred)))
# 学習データを用いたときの平均二乗誤差（MSE）を算出
print('MSE train data: ', mean_squared_error(Y_train, Y_train_pred)) 
# 検証データを用いたときの平均二乗誤差（MSE）を算出
print('MSE test data: ', mean_squared_error(Y_test, Y_pred))
```

　結果は以下のものになっています。これは場合によって異なる可能性がありますので気にしないでください。ここで、注目したいのは、学習データ、検証データそれぞれを用いたときの平均二乗誤差を比較すると、検証データを用いたときの誤差の方が大きいことです。このことは、構築した線形モデルは学習データにフィットしすぎている、すなわち**過学習**であることが示されています。

```python
RMSE train data:  6.043506135262846
RMSE test data:  6.807077593213252
MSE train data:  36.52396640695966
MSE test data:  46.336305360025925
```

### 決定係数

　決定係数とは、実際の値と予測値の絶対値の2乗を平均したものです。
　線形モデルの予測誤差を反映した指標であり、0~1の範囲の値をとり、1に近いほど説明変数が目的変数を説明していることになり、データに対して当てはまりの良いモデルであると言えます。

　また、式で示すと以下のように示されます。理解する必要は必ずしもありません。

$$ R^2 = 1 - \frac{\sum_{i=0}^{n-1} (y_i - \hat{y_i})^2}{\sum_{i=0}^{n-1} (y_i - \bar{y_i})^2} $$
$$但し、 y_i=実際の値、\hat{y}=予測値、 \bar{y}=平均値、n=データの総数 $$

　決定係数は、様々な算出方法がありますが、今回はLinearRegressionモデルのscoreメソッドで算出します。
　scoreの構文は以下の通りです。

```python
from sklearn.linear_model import LinearRegression
model = LinearRegression
model.score(Xデータ, Yデータ)
```

です。では、ボストンの住宅価格のデータセットに対して実際に決定係数を求めていきましょう。

###### <font color='red'>ボストンの住宅価格のデータセットに対して実際に決定係数を求めよう</font>

下記のコードを追加してみましょう。

```python
print('R^2 \n Train :' , model.score(X_train, Y_train), '\n Test :',model.score(X_test, Y_test))
```

　結果は以下のものになっています。MSEと同様に場合によって異なる可能性がありますので気にしないでください。ここで、注目したいのは、学習データ、検証データそれぞれを用いたときの決定係数を比較すると、検証データを用いたときの決定係数の方が小さいことです。このことからも、構築した単回帰モデルには過学習が起こっている可能性があることがわかります。

```python
R^2 
 Train : 0.571031588576562 
 Test : 0.43095672846187605
```

### 残差プロット
　残差プロットは、目的変数の真値と予測値の差分(残差)の分布をグラフ化したものです。モデルが目的変数を完璧に予測できる場合は残差は0となる性質を持っています。また、予測精度の良いモデルの残差プロットは、0を中心にランダムにばらついたものになります。
　残差プロットに何かパターンが見られる場合は、そのモデルで説明しきれない情報があることが示唆されます。

　残差とは以下のような部分のeの部分のことです。

![](/media/editor/D-6残差プロットの図形_20201130143155129984.png)

　残差が徐々に大きくあるいは小さくなっていたり、何かしらの傾向が見られる場合は要注意です。この場合、推定された回帰式が妥当ではない可能性があります。
　残差の評価は、縦軸の「0」に対して、残差がどのようにばらついているかをみてみましょう。残差が縦軸「0」に対して均一に分散している場合、大きな問題はありません。残差プロットの中で他とは異なり大きく外れている値が少数ある場合、該当する値は外れ値である可能性があるということです。

　それでは、ボストンの住宅価格のデータセットで残差を求めてみましょう。

　残差プロットは、目的変数の真値と予測値の差分(残差)の分布をグラフ化したものです。ですので、方針としては以下のようになります。

- ①(目的変数の実際の値) - (分析の結果得られた直線から出てきた予測値)を求めます
- 横軸に予測の目的変数をとって、縦軸に①の値をとってグラフ（散布図）にプロットします
- 学習データと検証データに分けてこれを行います


###### <font color='red'>実際にサブプロットを表示してみよう</font>

```python
# 学習用、検証用それぞれで残差をプロット
plt.scatter(Y_train_pred, Y_train_pred - Y_train, c = 'blue', marker = 'o', label = 'Train Data')
plt.scatter(Y_pred, Y_pred - Y_test, c = 'lightgreen', marker = 's', label = 'Test Data')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
# 凡例を左上に表示
plt.legend(loc = 'upper left')
# y = 0に直線を引く
plt.hlines(y = 0, xmin = -10, xmax = 50, lw = 2, color = 'red')
plt.xlim([10, 50])
plt.show()
```

　表示されたでしょうか？このままでは、グラフが２つ重なって表示されてしまい見にくいと思います。ですので、バラバラに表示するために少しコードを変更しましょう。scikit-learnのsubplotsというメソッドを使います。

　基本的にsubplotsの規則的に複数表示させるためのルールは以下のようになっています。

```python
subplot(行数, 列数, プロット番号)
```

　行数☓列数でfigureが分割されます。プロット番号は1行目から右方向に番号が増えるようにっており、ちなみに今回使ったのは1行2列なのでプロット番号は横方向に1,2と増えていきます。

詳しくは公式サイトを見てみましょう。
[subplotsの公式サイト](https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.subplots.html)

```python
# グラフを定義
# 見やすいようにサイズ調整
plt.subplots(figsize=(15, 5))
plt.subplot(1,2,1)
plt.scatter(xdata, ydata)
plt.subplot(1,2,1)
# すでにあるグラフを右側に表示しよう
plt.subplot(1,2,1)
plt.plot(xdata, model.predict(xdata), color="red")
plt.title("boston_housing")
plt.xlabel("LSTAT")
plt.ylabel("TARGET")
# 新しく作ったグラフを左側に表示しよう
plt.subplot(1,2,2)
plt.scatter(Y_train_pred, Y_train_pred - Y_train, c = 'blue', marker = 'o', label = 'Train Data')
plt.scatter(Y_pred, Y_pred - Y_test, c = 'lightgreen', marker = 's', label = 'Test Data')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
# 凡例を左上に表示
plt.legend(loc = 'upper left')
# y = 0に直線を引く
plt.hlines(y = 0, xmin = -10, xmax = 50, lw = 2, color = 'red')
plt.xlim([10, 50])
# グラフの表示
plt.show()
```

　すると、以下のようなグラフが表示されるはずです。

![](/media/editor/D-7残差プロットの結果_20201130143211119878.png)

　今回のモデルに関しては、概ねランダムに分布しているようにも見えますが、学習用データを使った場合の残差に関してグラフの右下になにか直線的な傾向があり、モデルに取り切れていない情報がある可能性があルといことがわかります。

# まとめ

　ここではモデルの性能を評価する方法を学習しました。これから違う学習方法を試していき、同様にモデルを評価してみましょう。
　それで、各モデルでの性能がどのようになるか見ていきましょう。